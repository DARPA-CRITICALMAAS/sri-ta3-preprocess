{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for steps in this processing code\n",
    "1. Define a base grid\n",
    "2. Load all the tif files - know how\n",
    "4. Load the shp files - know how\n",
    "5. Project the shp files to tif - at the resolution / bounds, etc with the base grid - know how\n",
    "6. Generate the train deposit / occurence tif files - know how\n",
    "6. Unify all the tif data - know how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import rasterio.features\n",
    "from s2sphere import CellId\n",
    "from shapely import Point\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import utilities as utils\n",
    "\n",
    "RAW_DATA_DIR = \"data/LAWLEY22-RAW/geophysics/\"\n",
    "DERIV_DATA_DIR = \"data/LAWLEY22-DERIV/geophysics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs, shps = utils.get_input_var_files(\"Australia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters = utils.load_rasters(tifs, rasters_path=RAW_DATA_DIR, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to upsample rasters that have too low a resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_raster = rasters[-1]\n",
    "for raster_idx, raster in enumerate(rasters):\n",
    "    if raster.res[0] <= base_raster.res[0]: continue\n",
    "    utils.resample_raster(base_raster, raster)\n",
    "    resampled_raster_file = f\"{tifs[raster_idx]}_resampled\"\n",
    "    rasters[raster_idx] = utils.load_raster(resampled_raster_file, verbosity=1)\n",
    "    tifs[raster_idx] = resampled_raster_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads rasters of the vector data if available; otherwise generates them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rasters += utils.load_rasters(shps, rasters_path=RAW_DATA_DIR, verbosity=1)\n",
    "except rasterio.RasterioIOError:\n",
    "    base_raster = rasters[-1] # defaults to intermediate resolution raster\n",
    "    vectors = utils.load_vectors(shps, vectors_path=RAW_DATA_DIR, verbosity=0)\n",
    "    pbar = tqdm(zip(shps, vectors))\n",
    "    for shp, vector in pbar:\n",
    "        pbar.set_description(f\"Processing {shp}\")\n",
    "        utils.proximity_raster_of_vector_points(base_raster, shp, vector)\n",
    "    rasters += utils.load_rasters(shps, rasters_path=RAW_DATA_DIR, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the base grid for all data if available; otherwise generates it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cell_file = f\"{DERIV_DATA_DIR}s2_grid_aus.npy\"\n",
    "try:\n",
    "    grid_cell_ids = np.load(grid_cell_file)\n",
    "except OSError:\n",
    "    grid_bounds = utils.compute_bounds(rasters, verbosity=1)\n",
    "    # gets all s2 cells\n",
    "    grid_cells = utils.region_of_cellids(grid_bounds, s2_level=12)\n",
    "    # filters s2 cells over water\n",
    "    ocean = utils.load_vector(\"ne_10m_ocean\",\"data/ocean/\",verbosity=0)\n",
    "    grid_cells = [grid_cell for grid_cell in grid_cells if not ocean[\"geometry\"][0].intersects(Point(utils.s2_cell_center(grid_cell)))]\n",
    "    # store remaining cell ids\n",
    "    grid_cell_ids = [grid_cell.id() for grid_cell in grid_cells]\n",
    "    np.save(grid_cell_file, np.asarray(grid_cell_ids, dtype=np.uint64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = utils.init_datacube({\"s2_cell_id\": grid_cell_ids}, [\"s2_cell_center\", \"s2_cell_poly\"] + tifs + shps, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file with Deposits and Occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep, df_occ = utils.process_raw_deposit_file('GeologyMineralOccurrences_USCanada_Australia.csv', csv_path='data/LAWLEY22-RAW/labels/', region='Australia', dep_grp='MVT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding MVT_Deposit, MVT_Occurrence columns to datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube, notrecogdep = utils.mvt_dep_occur_to_s2cells(datacube, df_dep, colname='MVT_Deposit')\n",
    "datacube, notrecogocc = utils.mvt_dep_occur_to_s2cells(datacube, df_occ, colname='MVT_Occurrence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add neighbors column to datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = utils.neighbor_deposits(datacube, deptype='MVT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the datacube using as many process as available CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datacube(row, cols):\n",
    "    s2cell = CellId(int(row[1][\"s2_cell_id\"]))\n",
    "    row[1][\"s2_cell_center\"] = utils.s2_cell_center(s2cell)\n",
    "    row[1][\"s2_cell_poly\"] = utils.s2_cell_polygon(s2cell)\n",
    "    for col, raster in zip(cols, utils.load_rasters(cols)):\n",
    "        try:\n",
    "            masked, _ = rasterio.mask.mask(raster, [row[1][\"s2_cell_poly\"]], crop=True)\n",
    "            if (raster.nodata == masked).all(): continue\n",
    "            row[1][col] = np.mean(masked[raster.nodata != masked])\n",
    "            row[1][\"mask\"] = True\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return row[1]\n",
    "\n",
    "# process_datacube_multi = partial(process_datacube, cols=tifs + shps, rass=rasters)\n",
    "process_datacube_multi = partial(process_datacube, cols=tifs + shps)\n",
    "\n",
    "# set up multiprocessing pool\n",
    "print(f\"Number of threads populating datacube - {mp.cpu_count()}\")\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# apply function to DataFrame in parallel\n",
    "results = []\n",
    "for result in tqdm(pool.imap(process_datacube_multi, datacube.iterrows()), total=datacube.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "# merge results back together\n",
    "datacube = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the datacube for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.to_csv(f\"{DERIV_DATA_DIR}datacube.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll rasterize the datacube to visualize it and confirm the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube[\"MVT_Deposit\"] = datacube[\"MVT_Deposit\"].astype(\"float64\")\n",
    "datacube[\"MVT_Occurrence\"] = datacube[\"MVT_Occurrence\"].astype(\"float64\")\n",
    "datacube[\"MVT_DepositOccurrence\"] = datacube[\"MVT_DepositOccurrence\"].astype(\"float64\")\n",
    "datacube[\"MVT_DepositOccurrenceNeighbors\"] = datacube[\"MVT_DepositOccurrenceNeighbors\"].astype(\"float64\")\n",
    "\n",
    "tif_layers = [col for col in datacube.columns.to_list() if \"s2\" not in col]\n",
    "\n",
    "base_raster = rasters[np.argmin([raster.res[0] for raster in rasters])] # defaults to highest resolution raster\n",
    "\n",
    "meta = base_raster.meta.copy()\n",
    "meta.update(compress='lzw')\n",
    "meta.update(dtype=\"float64\")\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tif_layer_idx, tif_layer in tqdm(enumerate(tif_layers), total=len(tif_layers)):\n",
    "    datacube_tif_file = f\"{DERIV_DATA_DIR}datacube_{tif_layer}.tif\"\n",
    "    with rasterio.open(datacube_tif_file, 'w+', **meta) as out:\n",
    "        out_arr = out.read(1)\n",
    "        # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "        shapes = list(datacube.loc[:,[\"s2_cell_poly\",tif_layer]].itertuples(index=False, name=None))\n",
    "        burned = rasterio.features.rasterize(shapes=shapes, fill=meta[\"nodata\"], out=out_arr, transform=out.transform)\n",
    "        out.write_band(1, burned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie-cmaas-pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
