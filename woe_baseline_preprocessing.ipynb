{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan for steps in this processing code\n",
    "1. Define a base grid\n",
    "2. Load all the tif files - know how\n",
    "4. Load the shp files - know how\n",
    "5. Project the shp files to tif - at the resolution / bounds, etc with the base grid - know how\n",
    "6. Generate the train deposit / occurence tif files - know how\n",
    "6. Unify all the tif data - know how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from s2sphere import CellId\n",
    "from shapely import Point\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import utilities as utils\n",
    "\n",
    "RAW_DATA_DIR = \"data/LAWLEY22-RAW/geophysics/\"\n",
    "DERIV_DATA_DIR = \"data/LAWLEY22-DERIV/geophysics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs, shps = utils.get_input_var_files(\"Australia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters = utils.load_rasters(tifs, rasters_path=RAW_DATA_DIR, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads rasters of the vector data if available; otherwise generates them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rasters += utils.load_rasters(shps, rasters_path=RAW_DATA_DIR, verbosity=1)\n",
    "except rasterio.RasterioIOError:\n",
    "    base_raster = rasters[-1] # defaults to intermediate resolution raster\n",
    "    vectors = utils.load_vectors(shps, vectors_path=RAW_DATA_DIR, verbosity=0)\n",
    "    pbar = tqdm(zip(shps, vectors))\n",
    "    for shp, vector in pbar:\n",
    "        pbar.set_description(f\"Processing {shp}\")\n",
    "        utils.proximity_raster_of_vector_points(base_raster, shp, vector)\n",
    "    rasters += utils.load_rasters(shps, rasters_path=RAW_DATA_DIR, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the base grid for all data if available; otherwise generates it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cell_file = f\"{DERIV_DATA_DIR}s2_grid_aus.npy\"\n",
    "try:\n",
    "    grid_cell_ids = np.load(grid_cell_file)\n",
    "except OSError:\n",
    "    grid_bounds = utils.compute_bounds(rasters, verbosity=1)\n",
    "    # gets all s2 cells\n",
    "    grid_cells = utils.region_of_cellids(grid_bounds, s2_level=12)\n",
    "    # filters s2 cells over water\n",
    "    ocean = utils.load_vector(\"ne_10m_ocean\",\"data/ocean/\",verbosity=0)\n",
    "    grid_cells = [grid_cell for grid_cell in grid_cells if not ocean[\"geometry\"][0].intersects(Point(utils.s2_cell_center(grid_cell)))]\n",
    "    # store remaining cell ids\n",
    "    grid_cell_ids = [grid_cell.id() for grid_cell in grid_cells]\n",
    "    np.save(grid_cell_file, np.asarray(grid_cell_ids, dtype=np.uint64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = utils.init_datacube({\"s2_cell_id\": grid_cell_ids}, [\"s2_cell_center\", \"s2_cell_poly\"] + tifs + shps, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the datacube using as many process as available CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datacube(row, cols):\n",
    "    s2cell = CellId(int(row[1][\"s2_cell_id\"]))\n",
    "    row[1][\"s2_cell_center\"] = utils.s2_cell_center(s2cell)\n",
    "    row[1][\"s2_cell_poly\"] = utils.s2_cell_polygon(s2cell)\n",
    "    for col, raster in zip(cols, utils.load_rasters(cols)):\n",
    "        try:\n",
    "            masked, _ = rasterio.mask.mask(raster, [row[1][\"s2_cell_poly\"]], crop=True)\n",
    "            if (raster.nodata == masked).all(): continue\n",
    "            row[1][col] = np.mean(masked[raster.nodata != masked])\n",
    "            row[1][\"mask\"] = True\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return row[1]\n",
    "\n",
    "# process_datacube_multi = partial(process_datacube, cols=tifs + shps, rass=rasters)\n",
    "process_datacube_multi = partial(process_datacube, cols=tifs + shps)\n",
    "\n",
    "# set up multiprocessing pool\n",
    "print(f\"Number of threads populating datacube - {mp.cpu_count()}\")\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# apply function to DataFrame in parallel\n",
    "results = []\n",
    "for result in tqdm(pool.imap(process_datacube_multi, datacube.iterrows()), total=datacube.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "# merge results back together\n",
    "datacube = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the datacube for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.to_csv(f\"{DERIV_DATA_DIR}datacube.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie-cmaas-pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
